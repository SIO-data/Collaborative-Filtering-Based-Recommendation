{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pk678PdTNtS8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../assets/data/recommendation_dataset.csv', sep=';')\n",
    "\n",
    "data.replace(99, np.nan, inplace=True)\n",
    "\n",
    "data.iloc[:, 0] = data.iloc[:, 0].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "data['DATASET'] = data['DATASET'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre cada columna (restaurante) para predecir los valores faltantes\n",
    "for column in data.columns[0:]:  # Ignorar la primera columna de nombres de usuarios\n",
    "    # Separar filas con datos conocidos y faltantes\n",
    "    known_data = data[data[column].notna()]\n",
    "    missing_data = data[data[column].isna()]\n",
    "\n",
    "    # Continuar solo si hay datos faltantes\n",
    "    if not missing_data.empty:\n",
    "        # Definir características y etiquetas\n",
    "        X_train = known_data.drop(columns=[column, 'DATASET'])\n",
    "        y_train = known_data[column]\n",
    "        X_missing = missing_data.drop(columns=[column, 'DATASET'])\n",
    "\n",
    "        # Entrenar el modelo de XGBoost\n",
    "        model = XGBRegressor(n_estimators=10, learning_rate=0.1, max_depth=1, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predecir los valores faltantes\n",
    "        predictions = model.predict(X_missing)\n",
    "\n",
    "        # Rellenar los valores predichos en el DataFrame\n",
    "        data.loc[data[column].isna(), column] = predictions\n",
    "\n",
    "# Guardar el DataFrame resultante\n",
    "print(\"Datos imputados:\")\n",
    "print(data.head())\n",
    "data.to_csv('../assets/data/dataset_XGBoost.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo valoraciones_completadasXGBoost.csv generado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "def cargar_base_csv(ruta_base):\n",
    "    \"\"\"Carga las valoraciones desde el archivo base.csv, omitiendo la primera fila.\"\"\"\n",
    "    with open(ruta_base, 'r') as archivo_base:\n",
    "        lector = csv.reader(archivo_base)\n",
    "        next(lector, None)  # Omitir la primera fila\n",
    "        return [list(map(float, fila)) for fila in lector]\n",
    "\n",
    "def poblar_valoraciones(ruta_base, ruta_valoraciones, ruta_salida):\n",
    "    \"\"\"Llena el archivo valoraciones.csv con las valoraciones de base.csv.\"\"\"\n",
    "    # Cargar las valoraciones desde base.csv\n",
    "    valoraciones_base = cargar_base_csv(ruta_base)\n",
    "\n",
    "    # Leer el archivo valoraciones.csv y procesar las líneas\n",
    "    with open(ruta_valoraciones, 'r') as archivo_val:\n",
    "        lector = csv.reader(archivo_val, delimiter=';')\n",
    "        filas_actualizadas = []\n",
    "        \n",
    "        for fila in lector:\n",
    "            usuario = int(fila[0].replace('User', '')) - 1  # Índice del usuario\n",
    "            restaurante = int(fila[1].replace('Restaurant', '')) - 1  # Índice del restaurante\n",
    "            valoracion = valoraciones_base[usuario][restaurante]  # Obtener la valoración\n",
    "            fila_actualizada = f\"{fila[0]};{fila[1]};{valoracion}\"\n",
    "            filas_actualizadas.append(fila_actualizada)\n",
    "\n",
    "    # Guardar las filas actualizadas en un archivo de salida\n",
    "    with open(ruta_salida, 'w') as archivo_salida:\n",
    "        for fila in filas_actualizadas:\n",
    "            archivo_salida.write(fila + '\\n')\n",
    "\n",
    "# Ejecución de la función\n",
    "ruta_base = '../assets/data/dataset_XGBoost.csv'\n",
    "ruta_valoraciones = '../assets/data/valoraciones.csv'\n",
    "ruta_salida = '../assets/data/dataset_result_XGBoost.csv'\n",
    "\n",
    "poblar_valoraciones(ruta_base, ruta_valoraciones, ruta_salida)\n",
    "print(\"Archivo dataset_result_XGBoost.csv generado exitosamente.\")\n",
    "print(\"python compute_mae.py target_recommendations.csv dataset_result_XGBoost.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
